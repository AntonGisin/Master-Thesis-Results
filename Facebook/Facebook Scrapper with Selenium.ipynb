{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36721142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeedc3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL = \"anton.gisin@mail.ru\"\n",
    "PASSWORD = \"Elblaze888\"\n",
    "\n",
    "\n",
    "def _extract_post_text(item):\n",
    "    actualPosts = item.find_all(attrs={\"data-testid\": \"post_message\"})\n",
    "    text = \"\"\n",
    "    if actualPosts:\n",
    "        for posts in actualPosts:\n",
    "            paragraphs = posts.find_all('p')\n",
    "            text = \"\"\n",
    "            for index in range(0, len(paragraphs)):\n",
    "                text += paragraphs[index].text\n",
    "    return text\n",
    "\n",
    "\n",
    "def _extract_link(item):\n",
    "    postLinks = item.find_all(class_=\"_6ks\")\n",
    "    link = \"\"\n",
    "    for postLink in postLinks:\n",
    "        link = postLink.find('a').get('href')\n",
    "    return link\n",
    "\n",
    "\n",
    "def _extract_post_id(item):\n",
    "    postIds = item.find_all(class_=\"_5pcq\")\n",
    "    post_id = \"\"\n",
    "    for postId in postIds:\n",
    "        post_id = f\"https://www.facebook.com{postId.get('href')}\"\n",
    "    return post_id\n",
    "\n",
    "\n",
    "def _extract_image(item):\n",
    "    postPictures = item.find_all(class_=\"scaledImageFitWidth img\")\n",
    "    image = \"\"\n",
    "    for postPicture in postPictures:\n",
    "        image = postPicture.get('src')\n",
    "    return image\n",
    "\n",
    "\n",
    "def _extract_shares(item):\n",
    "    postShares = item.find_all(class_=\"_4vn1\")\n",
    "    shares = \"\"\n",
    "    for postShare in postShares:\n",
    "\n",
    "        x = postShare.string\n",
    "        if x is not None:\n",
    "            x = x.split(\">\", 1)\n",
    "            shares = x\n",
    "        else:\n",
    "            shares = \"0\"\n",
    "    return shares\n",
    "\n",
    "\n",
    "def _extract_comments(item):\n",
    "    postComments = item.findAll(\"div\", {\"class\": \"_4eek\"})\n",
    "    comments = dict()\n",
    "    # print(postDict)\n",
    "    for comment in postComments:\n",
    "        if comment.find(class_=\"_6qw4\") is None:\n",
    "            continue\n",
    "\n",
    "        commenter = comment.find(class_=\"_6qw4\").text\n",
    "        comments[commenter] = dict()\n",
    "\n",
    "        comment_text = comment.find(\"span\", class_=\"_3l3x\")\n",
    "\n",
    "        if comment_text is not None:\n",
    "            comments[commenter][\"text\"] = comment_text.text\n",
    "\n",
    "        comment_link = comment.find(class_=\"_ns_\")\n",
    "        if comment_link is not None:\n",
    "            comments[commenter][\"link\"] = comment_link.get(\"href\")\n",
    "\n",
    "        comment_pic = comment.find(class_=\"_2txe\")\n",
    "        if comment_pic is not None:\n",
    "            comments[commenter][\"image\"] = comment_pic.find(class_=\"img\").get(\"src\")\n",
    "\n",
    "        commentList = item.find('ul', {'class': '_7791'})\n",
    "        if commentList:\n",
    "            comments = dict()\n",
    "            comment = commentList.find_all('li')\n",
    "            if comment:\n",
    "                for litag in comment:\n",
    "                    aria = litag.find(\"div\", {\"class\": \"_4eek\"})\n",
    "                    if aria:\n",
    "                        commenter = aria.find(class_=\"_6qw4\").text\n",
    "                        comments[commenter] = dict()\n",
    "                        comment_text = litag.find(\"span\", class_=\"_3l3x\")\n",
    "                        if comment_text:\n",
    "                            comments[commenter][\"text\"] = comment_text.text\n",
    "                            # print(str(litag)+\"\\n\")\n",
    "\n",
    "                        comment_link = litag.find(class_=\"_ns_\")\n",
    "                        if comment_link is not None:\n",
    "                            comments[commenter][\"link\"] = comment_link.get(\"href\")\n",
    "\n",
    "                        comment_pic = litag.find(class_=\"_2txe\")\n",
    "                        if comment_pic is not None:\n",
    "                            comments[commenter][\"image\"] = comment_pic.find(class_=\"img\").get(\"src\")\n",
    "\n",
    "                        repliesList = litag.find(class_=\"_2h2j\")\n",
    "                        if repliesList:\n",
    "                            reply = repliesList.find_all('li')\n",
    "                            if reply:\n",
    "                                comments[commenter]['reply'] = dict()\n",
    "                                for litag2 in reply:\n",
    "                                    aria2 = litag2.find(\"div\", {\"class\": \"_4efk\"})\n",
    "                                    if aria2:\n",
    "                                        replier = aria2.find(class_=\"_6qw4\").text\n",
    "                                        if replier:\n",
    "                                            comments[commenter]['reply'][replier] = dict()\n",
    "\n",
    "                                            reply_text = litag2.find(\"span\", class_=\"_3l3x\")\n",
    "                                            if reply_text:\n",
    "                                                comments[commenter]['reply'][replier][\n",
    "                                                    \"reply_text\"] = reply_text.text\n",
    "\n",
    "                                            r_link = litag2.find(class_=\"_ns_\")\n",
    "                                            if r_link is not None:\n",
    "                                                comments[commenter]['reply'][\"link\"] = r_link.get(\"href\")\n",
    "\n",
    "                                            r_pic = litag2.find(class_=\"_2txe\")\n",
    "                                            if r_pic is not None:\n",
    "                                                comments[commenter]['reply'][\"image\"] = r_pic.find(\n",
    "                                                    class_=\"img\").get(\"src\")\n",
    "    return comments\n",
    "\n",
    "\n",
    "def _extract_reaction(item):\n",
    "    toolBar = item.find_all(attrs={\"role\": \"toolbar\"})\n",
    "\n",
    "    if not toolBar:  # pretty fun\n",
    "        return\n",
    "    reaction = dict()\n",
    "    for toolBar_child in toolBar[0].children:\n",
    "        str = toolBar_child['data-testid']\n",
    "        reaction = str.split(\"UFI2TopReactions/tooltip_\")[1]\n",
    "\n",
    "        reaction[reaction] = 0\n",
    "\n",
    "        for toolBar_child_child in toolBar_child.children:\n",
    "\n",
    "            num = toolBar_child_child['aria-label'].split()[0]\n",
    "\n",
    "            # fix weird ',' happening in some reaction values\n",
    "            num = num.replace(',', '.')\n",
    "\n",
    "            if 'K' in num:\n",
    "                realNum = float(num[:-1]) * 1000\n",
    "            else:\n",
    "                realNum = float(num)\n",
    "\n",
    "            reaction[reaction] = realNum\n",
    "    return reaction\n",
    "\n",
    "\n",
    "def _extract_html(bs_data):\n",
    "\n",
    "    #Add to check\n",
    "    with open('./bs.html',\"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(str(bs_data.prettify()))\n",
    "\n",
    "    k = bs_data.find_all(class_=\"_5pcr userContentWrapper\")\n",
    "    postBigDict = list()\n",
    "\n",
    "    for item in k:\n",
    "        postDict = dict()\n",
    "        postDict['Post'] = _extract_post_text(item)\n",
    "        postDict['Link'] = _extract_link(item)\n",
    "        postDict['PostId'] = _extract_post_id(item)\n",
    "        postDict['Image'] = _extract_image(item)\n",
    "        postDict['Shares'] = _extract_shares(item)\n",
    "        postDict['Comments'] = _extract_comments(item)\n",
    "        # postDict['Reaction'] = _extract_reaction(item)\n",
    "\n",
    "        #Add to check\n",
    "        postBigDict.append(postDict)\n",
    "        with open('./postBigDict.json','w', encoding='utf-8') as file:\n",
    "            file.write(json.dumps(postBigDict, ensure_ascii=False).encode('utf-8').decode())\n",
    "\n",
    "    return postBigDict\n",
    "\n",
    "\n",
    "def _login(browser, email, password):\n",
    "    browser.get(\"http://facebook.com\")\n",
    "    browser.maximize_window()\n",
    "    browser.find_element_by_name(\"email\").send_keys(email)\n",
    "    browser.find_element_by_name(\"pass\").send_keys(password)\n",
    "    browser.find_element_by_id('loginbutton').click()\n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "def _count_needed_scrolls(browser, infinite_scroll, numOfPost):\n",
    "    if infinite_scroll:\n",
    "        lenOfPage = browser.execute_script(\n",
    "            \"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\"\n",
    "        )\n",
    "    else:\n",
    "        # roughly 8 post per scroll kindaOf\n",
    "        lenOfPage = int(numOfPost / 8)\n",
    "    print(\"Number Of Scrolls Needed \" + str(lenOfPage))\n",
    "    return lenOfPage\n",
    "\n",
    "\n",
    "def _scroll(browser, infinite_scroll, lenOfPage):\n",
    "    lastCount = -1\n",
    "    match = False\n",
    "\n",
    "    while not match:\n",
    "        if infinite_scroll:\n",
    "            lastCount = lenOfPage\n",
    "        else:\n",
    "            lastCount += 1\n",
    "\n",
    "        # wait for the browser to load, this time can be changed slightly ~3 seconds with no difference, but 5 seems\n",
    "        # to be stable enough\n",
    "        time.sleep(5)\n",
    "\n",
    "        if infinite_scroll:\n",
    "            lenOfPage = browser.execute_script(\n",
    "                \"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return \"\n",
    "                \"lenOfPage;\")\n",
    "        else:\n",
    "            browser.execute_script(\n",
    "                \"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return \"\n",
    "                \"lenOfPage;\")\n",
    "\n",
    "        if lastCount == lenOfPage:\n",
    "            match = True\n",
    "\n",
    "\n",
    "def extract(page, numOfPost, infinite_scroll=False, scrape_comment=False):\n",
    "    option = Options()\n",
    "    option.add_argument(\"--disable-infobars\")\n",
    "    option.add_argument(\"start-maximized\")\n",
    "    option.add_argument(\"--disable-extensions\")\n",
    "\n",
    "    # Pass the argument 1 to allow and 2 to block\n",
    "    option.add_experimental_option(\"prefs\", {\n",
    "        \"profile.default_content_setting_values.notifications\": 1\n",
    "    })\n",
    "\n",
    "    # chromedriver should be in the same folder as file\n",
    "    browser = webdriver.Chrome(executable_path='C:/Program Files (x86)/Google/Chrome/Application/chromedriver.exe', options=option)\n",
    "    _login(browser, EMAIL, PASSWORD)\n",
    "    browser.get(page)\n",
    "    lenOfPage = _count_needed_scrolls(browser, infinite_scroll, numOfPost)\n",
    "    _scroll(browser, infinite_scroll, lenOfPage)\n",
    "\n",
    "    # click on all the comments to scrape them all!\n",
    "    # TODO: need to add more support for additional second level comments\n",
    "    # TODO: ie. comment of a comment\n",
    "\n",
    "    if scrape_comment:\n",
    "        #first uncollapse collapsed comments\n",
    "        unCollapseCommentsButtonsXPath = '//a[contains(@class,\"_666h\")]'\n",
    "        unCollapseCommentsButtons = browser.find_elements_by_xpath(unCollapseCommentsButtonsXPath)\n",
    "        for unCollapseComment in unCollapseCommentsButtons:\n",
    "            action = webdriver.common.action_chains.ActionChains(browser)\n",
    "            try:\n",
    "                # move to where the un collapse on is\n",
    "                action.move_to_element_with_offset(unCollapseComment, 5, 5)\n",
    "                action.perform()\n",
    "                unCollapseComment.click()\n",
    "            except:\n",
    "                # do nothing right here\n",
    "                pass\n",
    "\n",
    "        #second set comment ranking to show all comments\n",
    "        rankDropdowns = browser.find_elements_by_class_name('_2pln') #select boxes who have rank dropdowns\n",
    "        rankXPath = '//div[contains(concat(\" \", @class, \" \"), \"uiContextualLayerPositioner\") and not(contains(concat(\" \", @class, \" \"), \"hidden_elem\"))]//div/ul/li/a[@class=\"_54nc\"]/span/span/div[@data-ordering=\"RANKED_UNFILTERED\"]'\n",
    "        for rankDropdown in rankDropdowns:\n",
    "            #click to open the filter modal\n",
    "            action = webdriver.common.action_chains.ActionChains(browser)\n",
    "            try:\n",
    "                action.move_to_element_with_offset(rankDropdown, 5, 5)\n",
    "                action.perform()\n",
    "                rankDropdown.click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # if modal is opened filter comments\n",
    "            ranked_unfiltered = browser.find_elements_by_xpath(rankXPath) # RANKED_UNFILTERED => (All Comments)\n",
    "            if len(ranked_unfiltered) > 0:\n",
    "                try:\n",
    "                    ranked_unfiltered[0].click()\n",
    "                except:\n",
    "                    pass    \n",
    "        \n",
    "        moreComments = browser.find_elements_by_xpath('//a[@class=\"_4sxc _42ft\"]')\n",
    "        print(\"Scrolling through to click on more comments\")\n",
    "        while len(moreComments) != 0:\n",
    "            for moreComment in moreComments:\n",
    "                action = webdriver.common.action_chains.ActionChains(browser)\n",
    "                try:\n",
    "                    # move to where the comment button is\n",
    "                    action.move_to_element_with_offset(moreComment, 5, 5)\n",
    "                    action.perform()\n",
    "                    moreComment.click()\n",
    "                except:\n",
    "                    # do nothing right here\n",
    "                    pass\n",
    "\n",
    "            moreComments = browser.find_elements_by_xpath('//a[@class=\"_4sxc _42ft\"]')\n",
    "\n",
    "    # Now that the page is fully scrolled, grab the source code.\n",
    "    source_data = browser.page_source\n",
    "\n",
    "    # Throw your source into BeautifulSoup and start parsing!\n",
    "    bs_data = bs(source_data, 'html.parser')\n",
    "\n",
    "    postBigDict = _extract_html(bs_data)\n",
    "    browser.close()\n",
    "\n",
    "    return postBigDict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "506435b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"loginbutton\"]\"}\n  (Session info: chrome=90.0.4430.212)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ca9bd10bf658>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpostBigDict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'WSJ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumOfPost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfinite_scroll\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscrape_comment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0musage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"CSV\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-54a481fc2a3e>\u001b[0m in \u001b[0;36mextract\u001b[1;34m(page, numOfPost, infinite_scroll, scrape_comment)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;31m# chromedriver should be in the same folder as file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[0mbrowser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C:/Program Files (x86)/Google/Chrome/Application/chromedriver.exe'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m     \u001b[0m_login\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEMAIL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPASSWORD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m     \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[0mlenOfPage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_count_needed_scrolls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfinite_scroll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumOfPost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-54a481fc2a3e>\u001b[0m in \u001b[0;36m_login\u001b[1;34m(browser, email, password)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"email\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memail\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpassword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m     \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loginbutton'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_id\u001b[1;34m(self, id_)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'foo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \"\"\"\n\u001b[1;32m--> 360\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"loginbutton\"]\"}\n  (Session info: chrome=90.0.4430.212)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   \n",
    "\n",
    "    postBigDict = extract(page='WSJ', numOfPost=10, infinite_scroll=False, scrape_comment=True)\n",
    "    \n",
    "    usage = \"CSV\"\n",
    "\n",
    "    #TODO: rewrite parser\n",
    "    if args.usage == \"WT\":\n",
    "        with open('output.txt', 'w') as file:\n",
    "            for post in postBigDict:\n",
    "                file.write(json.dumps(post))  # use json load to recover\n",
    "\n",
    "    elif usage == \"CSV\":\n",
    "        with open('data.tsv', 'w',) as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter='\\t')\n",
    "           #writer.writerow(['Post', 'Link', 'Image', 'Comments', 'Reaction'])\n",
    "            writer.writerow(['Post', 'Link', 'Image', 'Comments', 'Shares'])\n",
    "\n",
    "            for post in postBigDict:\n",
    "                writer.writerow([post['Post'], post['Link'],post['Image'], post['Comments'], post['Shares']])\n",
    "              #writer.writerow([post['Post'], post['Link'],post['Image'], post['Comments'], post['Reaction']])\n",
    "\n",
    "    else:\n",
    "        for post in postBigDict:\n",
    "            print(post)\n",
    "\n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee49520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
